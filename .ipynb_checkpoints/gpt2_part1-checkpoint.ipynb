{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a92b04-375e-4c21-8b7c-abbdd262ce83",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a643fd0-f160-425e-b489-6b86035e7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all.txt', 'r',encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dadd445-e876-4584-9de7-0f239659b7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length:  6340988\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset length: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9df7296-0d11-4722-9b81-e176604224bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HARRY POTTER AND THE CHAMBER OF SECRETS \\nby J. K. Rowling\\n\\u3000\\u3000(this is BOOK 2 in the Harry Potter series)\\n\\u3000\\u3000Original Scanned/OCR: Friday, April 07, 2000 v1.0 (edit where needed, change version number by 0.1)\\n\\u3000\\u3000CHAPTER\\tONE\\n\\u3000\\u3000THE WORST BIRTHDAY\\n\\u3000\\u3000Not for the first time, an argument had broken out over breakfast at number four, Privet Drive. Mr. Vernon Dursley had been woken in the early hours of the morning by a loud, hooting noise from his nephew Harry\\'s room.\\n\\u3000\\u3000\"Third time this week!\" he roared across the table. \"If you can\\'t control that owl, it\\'ll have to go!\"\\n\\u3000\\u3000Harry tried, yet again, to explain.\\n\\u3000\\u3000\"She\\'s bored,\" he said. \"She\\'s used to flying around outside. If I could just let her out at night -\"\\n\\u3000\\u3000\"Do I look stupid?\" snarled Uncle Vernon, a bit of fried egg dangling from his bushy mustache. \"I know what\\'ll happen if that owl\\'s let out.\"\\n\\u3000\\u3000He exchanged dark looks with his wife, Petunia.\\n\\u3000\\u3000Harry tried to argue back but his words were drowned by a long, loud belch from the Dursleys\\' son, Dudley.\\n\\u3000\\u30001\\n\\u3000\\u3000\"I want more bacon.\"\\n\\u3000\\u3000\"There\\'s more in the frying pan, sweetums,\" said Aunt Petunia, turning misty eyes on her massive son. \"We must build you up while we\\'ve got the chance .... I d'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5356f842-a6e8-4137-8d4d-0e30fc8b7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\u3000','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6557d8cf-be3b-44e4-8c8b-1a28f8803fcf",
   "metadata": {},
   "source": [
    "### Cleaning up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346f7fae-82b8-437b-a70d-bc0305896fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      "\f",
      "\u001f !\"$%&'()*,-./0123456789:;<=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz|}~é–—‘’“”…【】下为书件作你做全制区坛子式志您文新最本来格电的社立米糯自要论载\n",
      "vocab size:  136\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print('vocab size: ',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca7389fb-e340-4e0a-807d-d6fb9829fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_remove = \"“”…【】下为书件作你做全制区坛子式志您文新最本来格电的社立米糯自要论载~é–—‘’[]^_<>=`|}%\f",
    "\"\n",
    "trans_table = str.maketrans('', '', chars_to_remove)\n",
    "text = text.translate(trans_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdc8b4f-b74a-47af-b9c5-0237da600997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      "\u001f !\"$&'()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ\\abcdefghijklmnopqrstuvwxyz\n",
      "vocab size:  82\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print('vocab size: ',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91591283-e728-4bc5-adab-5ee31fc053e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_remove = chars[2]+chars[0]\n",
    "trans_table = str.maketrans('', '', chars_to_remove)\n",
    "text = text.translate(trans_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4c683-28ae-4116-be02-ae1be10fe982",
   "metadata": {},
   "source": [
    "# create the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88fe894-04da-4020-a24d-56df51bd8dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"$&'()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ\\abcdefghijklmnopqrstuvwxyz\n",
      "vocab size:  80\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print('vocab size: ',vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9481b36-60d5-4495-8c8b-d9995cb6339a",
   "metadata": {},
   "source": [
    "## Encoder and Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db99b9-84f1-47bb-acc7-c98e215b090c",
   "metadata": {},
   "source": [
    "#### here we will create out own character level encoder. OpenAI use tiktoken that does BPE encoding. Another popular tokeniser is sentence peice that does sub word encodings. After this is done, try another one with tiktoken and sentence piece encoding as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff6f2fb-9cb1-49d9-ba63-fafa3a950abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 58, 65, 65, 68, 1, 76, 68, 71, 65, 57]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars)}\n",
    "itos = { i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # takes in the string and outputs a list of integers for the characters of that string\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # taken in a list of inigers and outputs a corresponsing string\n",
    "\n",
    "print(encode('hello world'))\n",
    "print(decode(encode('hello world')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af66f1a7-362f-4be8-a37e-5274354146c8",
   "metadata": {},
   "source": [
    "#### let's tokenise the harry poter corpus based on the above tokeniser we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21892113-f17b-4815-844c-ed8edf5f3a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  torch.Size([6298015])\n",
      "tensor([34, 27, 44, 44, 51,  1, 42, 41, 46, 46, 31, 44,  1, 27, 40, 30,  1, 46,\n",
      "        34, 31,  1, 29, 34, 27, 39, 28, 31, 44,  1, 41, 32,  1, 45, 31, 29, 44,\n",
      "        31, 46, 45,  1,  0, 55, 78,  1, 36, 12,  1, 37, 12,  1, 44, 68, 76, 65,\n",
      "        62, 67, 60,  0,  7, 73, 61, 62, 72,  1, 62, 72,  1, 28, 41, 41, 37,  1,\n",
      "        16,  1, 62, 67,  1, 73, 61, 58,  1, 34, 54, 71, 71, 78,  1, 42, 68, 73,\n",
      "        73, 58, 71,  1, 72, 58, 71, 62, 58, 72,  8,  0, 41, 71, 62, 60, 62, 67,\n",
      "        54, 65,  1, 45, 56, 54, 67, 67, 58, 57, 13, 41, 29, 44, 24,  1, 32, 71,\n",
      "        62, 57, 54, 78, 10,  1, 27, 69, 71, 62, 65,  1, 14, 21, 10,  1, 16, 14,\n",
      "        14, 14,  1, 75, 15, 12, 14,  1,  7, 58, 57, 62, 73,  1, 76, 61, 58, 71,\n",
      "        58,  1, 67, 58, 58, 57, 58, 57, 10,  1, 56, 61, 54, 67, 60, 58,  1, 75,\n",
      "        58, 71, 72, 62, 68, 67,  1, 67, 74, 66, 55, 58, 71,  1, 55, 78,  1, 14,\n",
      "        12, 15,  8,  0, 29, 34, 27, 42, 46, 31, 44, 41, 40, 31,  0, 46, 34, 31,\n",
      "         1, 49, 41, 44, 45, 46,  1, 28, 35, 44, 46, 34, 30, 27, 51,  0, 40, 68,\n",
      "        73,  1, 59, 68, 71,  1, 73, 61, 58,  1, 59, 62, 71, 72, 73,  1, 73, 62,\n",
      "        66, 58, 10,  1, 54, 67,  1, 54, 71, 60, 74, 66, 58, 67, 73,  1, 61, 54,\n",
      "        57,  1, 55, 71, 68, 64, 58, 67,  1, 68, 74, 73,  1, 68, 75, 58, 71,  1,\n",
      "        55, 71, 58, 54, 64, 59, 54, 72, 73,  1, 54, 73,  1, 67, 74, 66, 55, 58,\n",
      "        71,  1, 59, 68, 74, 71, 10,  1, 42, 71, 62, 75, 58, 73,  1, 30, 71, 62,\n",
      "        75, 58, 12,  1, 39, 71, 12,  1, 48, 58, 71, 67, 68, 67,  1, 30, 74, 71,\n",
      "        72, 65, 58, 78,  1, 61, 54, 57,  1, 55, 58, 58, 67,  1, 76, 68, 64, 58,\n",
      "        67,  1, 62, 67,  1, 73, 61, 58,  1, 58, 54, 71, 65, 78,  1, 61, 68, 74,\n",
      "        71, 72,  1, 68, 59,  1, 73, 61, 58,  1, 66, 68, 71, 67, 62, 67, 60,  1,\n",
      "        55, 78,  1, 54,  1, 65, 68, 74, 57, 10,  1, 61, 68, 68, 73, 62, 67, 60,\n",
      "         1, 67, 68, 62, 72, 58,  1, 59, 71, 68, 66,  1, 61, 62, 72,  1, 67, 58,\n",
      "        69, 61, 58, 76,  1, 34, 54, 71, 71, 78,  6, 72,  1, 71, 68, 68, 66, 12,\n",
      "         0,  3, 46, 61, 62, 71, 57,  1, 73, 62, 66, 58,  1, 73, 61, 62, 72,  1,\n",
      "        76, 58, 58, 64,  2,  3,  1, 61, 58,  1, 71, 68, 54, 71, 58, 57,  1, 54,\n",
      "        56, 71, 68, 72, 72,  1, 73, 61, 58,  1, 73, 54, 55, 65, 58, 12,  1,  3,\n",
      "        35, 59,  1, 78, 68, 74,  1, 56, 54, 67,  6, 73,  1, 56, 68, 67, 73, 71,\n",
      "        68, 65,  1, 73, 61, 54, 73,  1, 68, 76, 65, 10,  1, 62, 73,  6, 65, 65,\n",
      "         1, 61, 54, 75, 58,  1, 73, 68,  1, 60, 68,  2,  3,  0, 34, 54, 71, 71,\n",
      "        78,  1, 73, 71, 62, 58, 57, 10,  1, 78, 58, 73,  1, 54, 60, 54, 62, 67,\n",
      "        10,  1, 73, 68,  1, 58, 77, 69, 65, 54, 62, 67, 12,  0,  3, 45, 61, 58,\n",
      "         6, 72,  1, 55, 68, 71, 58, 57, 10,  3,  1, 61, 58,  1, 72, 54, 62, 57,\n",
      "        12,  1,  3, 45, 61, 58,  6, 72,  1, 74, 72, 58, 57,  1, 73, 68,  1, 59,\n",
      "        65, 78, 62, 67, 60,  1, 54, 71, 68, 74, 67, 57,  1, 68, 74, 73, 72, 62,\n",
      "        57, 58, 12,  1, 35, 59,  1, 35,  1, 56, 68, 74, 65, 57,  1, 63, 74, 72,\n",
      "        73,  1, 65, 58, 73,  1, 61, 58, 71,  1, 68, 74, 73,  1, 54, 73,  1, 67,\n",
      "        62, 60, 61, 73,  1, 11,  3,  0,  3, 30, 68,  1, 35,  1, 65, 68, 68, 64,\n",
      "         1, 72, 73, 74, 69, 62, 57, 26,  3,  1, 72, 67, 54, 71, 65, 58, 57,  1,\n",
      "        47, 67, 56, 65, 58,  1, 48, 58, 71, 67, 68, 67, 10,  1, 54,  1, 55, 62,\n",
      "        73,  1, 68, 59,  1, 59, 71, 62, 58, 57,  1, 58, 60, 60,  1, 57, 54, 67,\n",
      "        60, 65, 62, 67, 60,  1, 59, 71, 68, 66,  1, 61, 62, 72,  1, 55, 74, 72,\n",
      "        61, 78,  1, 66, 74, 72, 73, 54, 56, 61, 58, 12,  1,  3, 35,  1, 64, 67,\n",
      "        68, 76,  1, 76, 61, 54, 73,  6, 65, 65,  1, 61, 54, 69, 69, 58, 67,  1,\n",
      "        62, 59,  1, 73, 61, 54, 73,  1, 68, 76, 65,  6, 72,  1, 65, 58, 73,  1,\n",
      "        68, 74, 73, 12,  3,  0, 34, 58,  1, 58, 77, 56, 61, 54, 67, 60, 58, 57,\n",
      "         1, 57, 54, 71, 64,  1, 65, 68, 68, 64, 72,  1, 76, 62, 73, 61,  1, 61,\n",
      "        62, 72,  1, 76, 62, 59, 58, 10,  1, 42, 58, 73, 74, 67, 62, 54, 12,  0,\n",
      "        34, 54, 71, 71, 78,  1, 73, 71, 62, 58, 57,  1, 73, 68,  1, 54, 71, 60,\n",
      "        74, 58,  1, 55, 54, 56, 64,  1, 55, 74, 73,  1, 61, 62, 72,  1, 76, 68,\n",
      "        71, 57, 72,  1, 76, 58, 71, 58,  1, 57, 71, 68, 76, 67, 58, 57,  1, 55,\n",
      "        78,  1, 54,  1, 65, 68, 67, 60, 10,  1, 65, 68, 74, 57,  1, 55, 58, 65,\n",
      "        56, 61,  1, 59, 71, 68, 66,  1, 73, 61, 58,  1, 30, 74, 71, 72, 65, 58,\n",
      "        78, 72,  6,  1, 72, 68, 67, 10,  1, 30, 74, 57, 65, 58, 78, 12,  0, 15,\n",
      "         0,  3, 35,  1, 76, 54, 67, 73,  1, 66])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text),dtype = torch.long)\n",
    "print('data shape: ',data.shape)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e63b2-ee69-452e-9802-100941d8e318",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f06c74-14a2-4d8c-9964-2935329dd7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n] #first 90%\n",
    "val_data = data[n:] #last 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d30ce021-22b2-44eb-8b28-e10e21bc71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8 #context length of our model will be block_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "108394d2-ff0c-404b-8c95-304280fc138f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When output is H the target is A\n",
      "When output is HA the target is R\n",
      "When output is HAR the target is R\n",
      "When output is HARR the target is Y\n",
      "When output is HARRY the target is  \n",
      "When output is HARRY  the target is P\n",
      "When output is HARRY P the target is O\n",
      "When output is HARRY PO the target is T\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"When output is {decode(context.tolist())} the target is {decode([target.item()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eadd83f-81c8-40f4-9f36-c75f87e2d081",
   "metadata": {},
   "source": [
    "#### adding the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31dcf137-342a-4f6b-9771-599c3d3dc5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  torch.Size([4, 8])  : \n",
      " tensor([[67, 57,  1, 57, 58, 72, 58, 71],\n",
      "        [58, 57,  1, 54, 67, 57,  1, 59],\n",
      "        [62, 57,  1,  0, 78, 68, 74,  1],\n",
      "        [67, 57, 68, 71, 12,  1, 51, 68]])\n",
      "targets:  torch.Size([4, 8])  : \n",
      " tensor([[57,  1, 57, 58, 72, 58, 71, 73],\n",
      "        [57,  1, 54, 67, 57,  1, 59, 71],\n",
      "        [57,  1,  0, 78, 68, 74,  1, 58],\n",
      "        [57, 68, 71, 12,  1, 51, 68, 74]])\n",
      "--------\n",
      "when out put in n the target: d\n",
      "when out put in nd the target:  \n",
      "when out put in nd  the target: d\n",
      "when out put in nd d the target: e\n",
      "when out put in nd de the target: s\n",
      "when out put in nd des the target: e\n",
      "when out put in nd dese the target: r\n",
      "when out put in nd deser the target: t\n",
      "when out put in e the target: d\n",
      "when out put in ed the target:  \n",
      "when out put in ed  the target: a\n",
      "when out put in ed a the target: n\n",
      "when out put in ed an the target: d\n",
      "when out put in ed and the target:  \n",
      "when out put in ed and  the target: f\n",
      "when out put in ed and f the target: r\n",
      "when out put in i the target: d\n",
      "when out put in id the target:  \n",
      "when out put in id  the target: \n",
      "\n",
      "when out put in id \n",
      " the target: y\n",
      "when out put in id \n",
      "y the target: o\n",
      "when out put in id \n",
      "yo the target: u\n",
      "when out put in id \n",
      "you the target:  \n",
      "when out put in id \n",
      "you  the target: e\n",
      "when out put in n the target: d\n",
      "when out put in nd the target: o\n",
      "when out put in ndo the target: r\n",
      "when out put in ndor the target: .\n",
      "when out put in ndor. the target:  \n",
      "when out put in ndor.  the target: Y\n",
      "when out put in ndor. Y the target: o\n",
      "when out put in ndor. Yo the target: u\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # homany indipendent sequences we will process in parallel\n",
    "block_size = 8 # maximum context length\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size,(batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "print('inputs: ', xb.shape, ' : \\n',xb)\n",
    "print('targets: ', yb.shape, ' : \\n',yb)\n",
    "print('--------')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when out put in {decode(context.tolist())} the target: {decode([target.item()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd4a6b-83a0-4c9c-96c8-e9599267fd30",
   "metadata": {},
   "source": [
    "# Let's start feeding this into the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b35b383f-0e61-47f6-a2d3-b85470ff570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[67, 57,  1, 57, 58, 72, 58, 71],\n",
      "        [58, 57,  1, 54, 67, 57,  1, 59],\n",
      "        [62, 57,  1,  0, 78, 68, 74,  1],\n",
      "        [67, 57, 68, 71, 12,  1, 51, 68]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # out input to the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83179d-6392-4c9a-a587-cdfb73899e71",
   "metadata": {},
   "source": [
    "#### we will start with a bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fe2cb38-0712-4708-b5b9-9e9d09f2aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 80])\n",
      "Loss:  4.717065334320068\n",
      "\n",
      "eoK6KGlKhxi(NQ/9-i4$K6;i8UJA5PMip7.wOS?-aD6\\!:wCI82(u5PXNNQT*H8B$C1sIWA-jxm7a:D:DloRhiQc.LA2afnXZQ-R\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits,targets) #neg log likelihood loss\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current index\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(idx)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx,idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print('Loss: ',loss.item())\n",
    "\n",
    "print(decode(m.generate(torch.zeros((1,1),dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f05ff8-b806-446f-9d1e-ed62d8e8931c",
   "metadata": {},
   "source": [
    "# Let's train the model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bc76f04-8e0b-4e87-a7c3-2f72152651e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an optamizer object\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(),lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5da9bc66-c006-4b22-9b72-be14545d7ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.447514533996582\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    xb,yb = get_batch('train')\n",
    "    logits,loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b73e6fb4-77a3-40f6-9286-33035bbc8221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\"SThes outint wn'st hesm \" s facumstle. .\n",
      "\" Cof t m ws  s s he, atmeeawanong trley the wh s peace..\n",
      "G blon. ltheroned dil.\n",
      "yof tr howowa g, f w t tht, aglof.\n",
      "OUmput, ontit onthind br; seantheauthenalsh thigher agaly.. a \n",
      " tshack hinlle dindsowimbo m Whey ort ggouthe icar Hentifof ashin'\n",
      "\"Welof withanct ct?\"Lulal thamm wan't batis ckenckne as! Mch, fbown ve trad. he wad.\n",
      "Weve t Mo'SKind 'Ealorr wousuthomutist,\"Yowe ing cof s nestistr bered de. frysisthin tcarobed, womig.  s Th its -gs se  in p \n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1),dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f157e5c0-caf8-4294-8434-3bf1b4d57286",
   "metadata": {},
   "source": [
    "# let's see how attention works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b532894-d26b-4fdf-8381-1aed3bae9d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4dfed1f0-9305-459d-987a-4ed2d13a3787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "query = nn.Linear(C, head_size, bias= False)\n",
    "value = nn.Linear(C, head_size, bias= False)\n",
    "\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "v = value(x)\n",
    "\n",
    "wei = q@k.transpose(-2,-1)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril ==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dd5c0a0-66e7-441a-bd08-6bbf2ee02d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0072, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0357, 0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0331, 0.0913, 0.0883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4802, 0.2227, 0.3702, 0.1406, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0126, 0.2006, 0.0727, 0.2308, 0.2723, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2243, 0.1704, 0.1866, 0.1144, 0.2476, 0.8089, 0.0000, 0.0000],\n",
       "         [0.1780, 0.2286, 0.1284, 0.1971, 0.3023, 0.1293, 0.5951, 0.0000],\n",
       "         [0.0290, 0.0334, 0.1537, 0.3171, 0.1778, 0.0618, 0.4049, 1.0000]],\n",
       "\n",
       "        [[0.0083, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4076, 0.0311, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0011, 0.3741, 0.2578, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0793, 0.1331, 0.0080, 0.0559, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0258, 0.0924, 0.0559, 0.3522, 0.2261, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2555, 0.2333, 0.1053, 0.0097, 0.5588, 0.9416, 0.0000, 0.0000],\n",
       "         [0.1922, 0.0365, 0.5114, 0.3722, 0.1665, 0.0219, 0.6517, 0.0000],\n",
       "         [0.0303, 0.0995, 0.0616, 0.2100, 0.0486, 0.0366, 0.3483, 1.0000]],\n",
       "\n",
       "        [[0.0182, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0442, 0.0989, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3210, 0.0996, 0.0883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0691, 0.1407, 0.0225, 0.1134, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1119, 0.1498, 0.2889, 0.6924, 0.0184, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0778, 0.1071, 0.4805, 0.0979, 0.0818, 0.0788, 0.0000, 0.0000],\n",
       "         [0.1489, 0.1910, 0.0593, 0.0868, 0.0240, 0.2187, 0.8735, 0.0000],\n",
       "         [0.2090, 0.2129, 0.0604, 0.0095, 0.8758, 0.7026, 0.1265, 1.0000]],\n",
       "\n",
       "        [[0.1251, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1015, 0.0154, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1387, 0.0360, 0.2419, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0083, 0.1737, 0.0463, 0.3921, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2975, 0.0503, 0.1478, 0.0121, 0.1287, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0137, 0.0225, 0.2920, 0.4986, 0.6963, 0.0396, 0.0000, 0.0000],\n",
       "         [0.1206, 0.6350, 0.0569, 0.0417, 0.0899, 0.8728, 0.2326, 0.0000],\n",
       "         [0.1947, 0.0671, 0.2150, 0.0556, 0.0851, 0.0876, 0.7674, 1.0000]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c6f12-3d44-49cd-a04b-ec126bcf5b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karpathyZ2H",
   "language": "python",
   "name": "karpathyz2h"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
